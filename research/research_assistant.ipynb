{
 "cells": [
  {
   "cell_type": "code",
   "id": "c73c7a35bf7aec89",
   "metadata": {},
   "source": [
    "# Common utilities for web search\n",
    "from duckduckgo_search import DDGS\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class WebSearchTool:\n",
    "    def search(self, query: str, num_results: int = 5) -> List[Dict]:\n",
    "        with DDGS() as ddgs:\n",
    "            results = list(ddgs.text(query, max_results=num_results))\n",
    "        return results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "74a27a7868204556",
   "metadata": {},
   "source": [
    "# OpenAI Implementation\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "\n",
    "class OpenAIResearchAgent:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.web_search = WebSearchTool()\n",
    "\n",
    "        # Define custom functions for the assistant\n",
    "        self.tools = [{\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"search_internet\",\n",
    "                \"description\": \"Search the internet for information\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The search query\"\n",
    "                        },\n",
    "                        \"num_results\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"Number of results to return\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                }\n",
    "            }\n",
    "        }]\n",
    "\n",
    "        # Create an assistant\n",
    "        self.assistant = self.client.beta.assistants.create(\n",
    "            name=\"Research Agent\",\n",
    "            instructions=\"\"\"You are a research agent that:\n",
    "                1. Searches the internet for current information\n",
    "                2. Analyzes and synthesizes found information\n",
    "                3. Provides detailed summaries with citations\n",
    "                4. Suggests follow-up research areas\n",
    "                When searching, break down complex queries into specific searchable terms.\"\"\",\n",
    "            model=\"gpt-4-turbo-preview\",\n",
    "            tools=self.tools\n",
    "        )\n",
    "\n",
    "    def search_internet(self, query: str, num_results: int = 5) -> str:\n",
    "        results = self.web_search.search(query, num_results)\n",
    "        return json.dumps(results)\n",
    "\n",
    "    def start_research(self, query: str) -> str:\n",
    "        # Create a thread\n",
    "        thread = self.client.beta.threads.create()\n",
    "\n",
    "        # Add the initial message\n",
    "        # message = self.client.beta.threads.messages.create(\n",
    "        #     thread_id=thread.id,\n",
    "        #     role=\"user\",\n",
    "        #     content=query\n",
    "        # )\n",
    "\n",
    "        # Run the assistant\n",
    "        run = self.client.beta.threads.runs.create(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=self.assistant.id\n",
    "        )\n",
    "\n",
    "        # Handle tool calls\n",
    "        while run.status in [\"queued\", \"in_progress\"]:\n",
    "            run = self.client.beta.threads.runs.retrieve(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id\n",
    "            )\n",
    "\n",
    "            if run.status == \"requires_action\":\n",
    "                tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "                tool_outputs = []\n",
    "\n",
    "                for tool_call in tool_calls:\n",
    "                    if tool_call.function.name == \"search_internet\":\n",
    "                        args = json.loads(tool_call.function.arguments)\n",
    "                        output = self.search_internet(args[\"query\"], args.get(\"num_results\", 5))\n",
    "                        tool_outputs.append({\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"output\": output\n",
    "                        })\n",
    "\n",
    "                run = self.client.beta.threads.runs.submit_tool_outputs(\n",
    "                    thread_id=thread.id,\n",
    "                    run_id=run.id,\n",
    "                    tool_outputs=tool_outputs\n",
    "                )\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        # Get the final response\n",
    "        messages = self.client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        return messages.data[0].content[0].text.value"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb29415651b407e7",
   "metadata": {},
   "source": [
    "# Anthropic Implementation\n",
    "from anthropic import Anthropic\n",
    "\n",
    "class AnthropicResearchAgent:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.web_search = WebSearchTool()\n",
    "        self.memory = []\n",
    "\n",
    "    def _create_system_prompt(self):\n",
    "        return \"\"\"You are a research agent that systematically:\n",
    "            1. Searches the internet for current information\n",
    "            2. Analyzes and synthesizes search results\n",
    "            3. Maintains context across interactions\n",
    "            4. Provides citations for all findings\n",
    "            5. Suggests related research directions\"\"\"\n",
    "\n",
    "    def process_query(self, query: str) -> str:\n",
    "        # First, perform a web search\n",
    "        search_results = self.web_search.search(query)\n",
    "\n",
    "        # Create messages with memory and search results\n",
    "        messages = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": self._create_system_prompt()\n",
    "        }] + self.memory + [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Query: {query}\n",
    "\n",
    "            Search Results:\n",
    "            {json.dumps(search_results, indent=2)}\n",
    "\n",
    "            Please analyze these results and provide a comprehensive response.\"\"\"\n",
    "        }]\n",
    "\n",
    "        # Get response using Claude\n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-3-opus-20240229\",\n",
    "            max_tokens=2000,\n",
    "            messages=messages,\n",
    "            tools=[{\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"perform_additional_search\",\n",
    "                    \"description\": \"Perform additional internet search\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\"type\": \"string\"},\n",
    "                            \"num_results\": {\"type\": \"integer\"}\n",
    "                        },\n",
    "                        \"required\": [\"query\"]\n",
    "                    }\n",
    "                }\n",
    "            }]\n",
    "        )\n",
    "\n",
    "        # Update memory\n",
    "        self.memory.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        })\n",
    "        self.memory.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response.content[0].text\n",
    "        })\n",
    "\n",
    "        return response.content[0].text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "393751a60d2b44d8",
   "metadata": {},
   "source": [
    "# Google Gemini Implementation\n",
    "# import google.generativeai as genai\n",
    "from google import genai\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "class GeminiResearchAgent:\n",
    "    def __init__(self, api_key):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel('gemini-pro')\n",
    "        self.chat = self.model.start_chat(history=[])\n",
    "        self.web_search = WebSearchTool()\n",
    "        self.setup_database()\n",
    "        self.conn = None\n",
    "\n",
    "    def setup_database(self):\n",
    "        self.conn = sqlite3.connect('research_memory.db')\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self.cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS research_memory\n",
    "            (timestamp TEXT, topic TEXT, findings TEXT, sources TEXT)\n",
    "        ''')\n",
    "        self.conn.commit()\n",
    "\n",
    "    def store_memory(self, topic: str, findings: str, sources: List[str]):\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        self.cursor.execute(\n",
    "            'INSERT INTO research_memory VALUES (?, ?, ?, ?)',\n",
    "            (timestamp, topic, findings, json.dumps(sources))\n",
    "        )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def get_related_memories(self, topic: str) -> List[Dict]:\n",
    "        self.cursor.execute(\n",
    "            'SELECT findings, sources FROM research_memory WHERE topic LIKE ?',\n",
    "            (f'%{topic}%',)\n",
    "        )\n",
    "        results = []\n",
    "        for row in self.cursor.fetchall():\n",
    "            results.append({\n",
    "                'findings': row[0],\n",
    "                'sources': json.loads(row[1])\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    def research_topic(self, query: str) -> str:\n",
    "        # Perform web search\n",
    "        search_results = self.web_search.search(query)\n",
    "\n",
    "        # Get related previous research\n",
    "        related_memories = self.get_related_memories(query)\n",
    "\n",
    "        # Create context-aware prompt\n",
    "        context = f\"\"\"Research Query: {query}\n",
    "\n",
    "        New Search Results:\n",
    "        {json.dumps(search_results, indent=2)}\n",
    "\n",
    "        Previous Related Research:\n",
    "        {\n",
    "            json.dumps(related_memories, indent=2) \n",
    "            if related_memories \n",
    "            else 'No previous research found.'\n",
    "        }\n",
    "\n",
    "        Please analyze this topic considering:\n",
    "        1. Key findings from search results\n",
    "        2. Integration with previous research\n",
    "        3. Practical applications\n",
    "        4. Future implications\n",
    "\n",
    "        Provide citations for all information.\"\"\"\n",
    "\n",
    "        # Get response from Gemini\n",
    "        response = self.chat.send_message({\n",
    "            'contents': [{\n",
    "                'role': \"user\",\n",
    "                'parts': [{'text': context}]\n",
    "            }],\n",
    "            'tools': [{\n",
    "                'name': 'research_analysis',\n",
    "                'parameters': {\n",
    "                    'depth': 'comprehensive',\n",
    "                    'focus': 'technical and practical'\n",
    "                }\n",
    "            }]\n",
    "        })\n",
    "\n",
    "        # Store the findings with sources\n",
    "        self.store_memory(\n",
    "            query,\n",
    "            response.text,\n",
    "            [result['link'] for result in search_results]\n",
    "        )\n",
    "\n",
    "        return response.text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc4184d8065e19bc",
   "metadata": {},
   "source": [
    "# Example usage for each agent\n",
    "def demonstrate_agents():\n",
    "    # OpenAI example\n",
    "    openai_agent = OpenAIResearchAgent(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    openai_result = openai_agent.start_research(\n",
    "        \"What are the latest developments in fusion energy research?\"\n",
    "    )\n",
    "    print(\"OpenAI Agent Results:\", openai_result)\n",
    "\n",
    "    # Anthropic example\n",
    "    # anthropic_agent = AnthropicResearchAgent(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "    # anthropic_result = anthropic_agent.process_query(\n",
    "    #     \"What are the current challenges in quantum computing?\"\n",
    "    # )\n",
    "    # print(\"Anthropic Agent Results:\", anthropic_result)\n",
    "\n",
    "    # Gemini example\n",
    "    # gemini_agent = GeminiResearchAgent(os.environ.get(\"GOOGLE_GEMINI_API_KEY\"))\n",
    "    # gemini_result = gemini_agent.research_topic(\n",
    "    #     \"How is AI being used in climate change mitigation?\"\n",
    "    # )\n",
    "    # print(\"Gemini Agent Results:\", gemini_result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f60e5aee",
   "metadata": {},
   "source": [
    "demonstrate_agents()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "627dceb5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
